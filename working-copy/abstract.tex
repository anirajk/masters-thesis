%%% -*-LaTeX-*-
%%% This is the abstract for the thesis.
%%% It is included in the top-level LaTeX file with
%%%
%%%    \preface    {abstract} {Abstract}
%%%
%%% The first argument is the basename of this file, and the
%%% second is the title for this page, which is thus not
%%% included here.
%%%
%%% The text of this file should be about 350 words or less.

%K most systems optimise for small responses, others require hardware software balance


Efficient movement of massive amounts of data over high-speed networks at high 
throughput is essential for a modern day In-memory storage system.

In response to the growing needs of throughput and latency demands at scale, a new class of database systems was developed in recent years.
The development of these systems was guided by increased access to high throughput, low latency network fabrics and declining cost of Dynamic Random Access Memory(DRAM).

These systems were designed with On Line Transactional Processing (OLTP) workloads in mind and, as a result, are optimized for fast dispatch and performs well under small
request-response scenarios. However, massive server responses such as those for range queries and data migration for load balancing poses challenges for this design.  

This thesis analyzes the effects of large transfers on scale-out systems through the lens of a modern Network Interface Card (NIC).
The present-day NIC offers new and exciting opportunities and challenges for large transfers.
We can make them efficient by leveraging smart data layout and concurrency control.

We evaluated the impact of modern NICs in designing data layout by measuring transmit performance and full system impact by observing the effects of Direct Memory Access (DMA), Remote Direct Memory Access (RDMA) and caching improvements such as Data Direct I/O\textregistered (DDIO). 

We discovered that use of techniques such as Zero Copy yield around 25\% savings in CPU cycles and a 50\% reduction in the memory pressure on the system. 

We also set up experiments that underlined the bottlenecks in the current approach to data migration in RAMCloud and propose guidelines for a fast and efficient migration protocol for RAMCloud.
